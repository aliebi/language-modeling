{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliebi/language-modeling/blob/master/LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4h68x_z2bjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UONgiqAs7kRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *\n",
        "import fastai.utils.collect_env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3sqt7g07RMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bs=48\n",
        "# bs=24\n",
        "bs=192"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oBMgeVs7Wvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsDu53IxE5N2",
        "colab_type": "text"
      },
      "source": [
        "read full dataset of imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcF14s1h8hIF",
        "colab_type": "code",
        "outputId": "468dffe3-110d-4a10-e3f0-6fd667e61370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "path = untar_data(URLs.IMDB)\n",
        "path.ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb/unsup'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_lm'),\n",
              " PosixPath('/root/.fastai/data/imdb/train'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_clas'),\n",
              " PosixPath('/root/.fastai/data/imdb/imdb.vocab'),\n",
              " PosixPath('/root/.fastai/data/imdb/test'),\n",
              " PosixPath('/root/.fastai/data/imdb/README')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0lubrET8kJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data_lm = (TextList.from_folder(path)\n",
        "           #Inputs: all the text files in path\n",
        "            .filter_by_folder(include=['train', 'test', 'unsup']) \n",
        "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
        "            .split_by_rand_pct(0.1, seed=42)\n",
        "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
        "            .label_for_lm()           \n",
        "           #We want to do a language model so we label accordingly\n",
        "            .databunch(bs=bs, num_workers=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm7VLiROBQVn",
        "colab_type": "code",
        "outputId": "2b97b9cd-9fc4-4262-a3e7-e9114c18d26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_lm.vocab.itos),len(data_lm.train_ds)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 90000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh-BkBjzB-FS",
        "colab_type": "code",
        "outputId": "be2bc319-47b8-4061-9c3a-e3daa684c2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>of the time i find her shtick a little tedious , and where i really like her as a supporting player , when she 's the lead i start to get a headache . xxmaj perhaps that 's just me , but if you ever thought she may be a little over the top , this is not the film for you . \\n \\n  xxmaj paul xxmaj rudd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>transformation from troubled people to those xxunk having been made to accept being xxunk who have lost everything they have and thereof can do anything , regardless of any value and concept associated with humanity such as love , affection , empathy , honor , self - respect . xxmaj the psychos in the movie had n't committed any crime till the story , none was recorded a least .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>of the titles for this release ) although the pictures sometimes show nothing more than xxmaj ornella xxmaj muti naked in a photo - me - booth . xxmaj they end up in the mansion of a rich lady ( xxmaj irene xxmaj pappas giving a performance less lively than some of the furniture and obviously wishing she were elsewhere ) because they run out of gasoline , and when</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>be different if something happened at all in the film ... it does not . xxmaj just try to think of xxmaj curse of the xxmaj screaming xxmaj dead / xxmaj curse of the xxmaj cannibal xxmaj confederates xxup without xxup any xxup zombies . xxmaj yes , i am serious . xxmaj that is just what this film is . \\n \\n  xxmaj honestly ... this is the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>is just seriously a bad time . xxmaj the first few minutes are good enough , with a good film score . xxmaj from the start , you begin to sense that this is an atmospheric film that may lose you in its boredom sometimes but still maintain enough of an edge to hold you for the xxunk hour running length . xxmaj fulci gets a lot of credit for</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EILQn863CWh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('lm_databunch')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq762119Cc5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'lm_databunch', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfRdQDNoFQXl",
        "colab_type": "text"
      },
      "source": [
        "here we make LM for our imdb dataset that "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgpfLRWADF8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHlLpo9sGTND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_itos = pickle.load(open(Config().model_path()/'wt103-fwd/itos_wt103.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjThynu9PjEY",
        "colab_type": "code",
        "outputId": "9f14c46d-e1f1-4d07-b9ef-28a32244e579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(wiki_itos)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AyNis7q66Ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_itos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIIMpny57BAj",
        "colab_type": "code",
        "outputId": "25393cb1-f330-49d3-bcb6-0ebf7a405308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "vocab = data_lm.vocab\n",
        "vocab.stoi['green']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itgZL5777xCs",
        "colab_type": "code",
        "outputId": "f3be6956-df87-4482-ab35-bfec90b4b6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "vocab.itos[vocab.stoi[\"green\"]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'green'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd3M9C6y77hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "awd = learn_lm.model[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-LYDuPjZ5q8",
        "colab_type": "text"
      },
      "source": [
        "# Difference in vocabulary between IMDB and Wikipedia\n",
        " It is to be expected that the two sets have some different vocabulary words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x1AOfMiaK15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a84524d2-2bee-487e-ab9f-10b667b2f1ad"
      },
      "source": [
        "len(wiki_itos),len(vocab.itos)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9--HLNxa288",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "i, unks = 0, []\n",
        "while len(unks) < 50:\n",
        "    if data_lm.vocab.itos[i] not in wiki_itos: unks.append((i,data_lm.vocab.itos[i]))\n",
        "    i += 1\n",
        "    \n",
        "    \n",
        "wiki_words = set(wiki_itos)\n",
        "\n",
        "imdb_words = set(vocab.itos)\n",
        "\n",
        "wiki_not_imbdb = wiki_words.difference(imdb_words)\n",
        "\n",
        "imdb_not_wiki = imdb_words.difference(wiki_words)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "wiki_not_imdb_list = []\n",
        "\n",
        "for i in range(100):\n",
        "    word = wiki_not_imbdb.pop()\n",
        "    wiki_not_imdb_list.append(word)\n",
        "    wiki_not_imbdb.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8whXcz37bRMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "42e87c7b-6345-4d93-b613-a0141e81d838"
      },
      "source": [
        "wiki_not_imdb_list[:15]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bulliard',\n",
              " 'ung',\n",
              " 'polyps',\n",
              " '1035',\n",
              " 'rodrigues',\n",
              " 'groupe',\n",
              " 'bajrang',\n",
              " 'jackalope',\n",
              " 'harclay',\n",
              " 'barbossa',\n",
              " 'achtung',\n",
              " 'glazing',\n",
              " 'retook',\n",
              " 'thistle',\n",
              " 'speciation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3N8OkoBbSny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_not_wiki_list = []\n",
        "\n",
        "for i in range(100):\n",
        "    word = imdb_not_wiki.pop()\n",
        "    imdb_not_wiki_list.append(word)\n",
        "    imdb_not_wiki.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQpxopJRbVyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "e1bed93d-c335-46ac-d6bc-067668713b4a"
      },
      "source": [
        "imdb_not_wiki_list[:15]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['desecrate',\n",
              " 'desny',\n",
              " 'encolpio',\n",
              " 'fragata',\n",
              " 'curdling',\n",
              " 'popstar',\n",
              " 'senar',\n",
              " 'yuelin',\n",
              " 'reawaken',\n",
              " 'tp',\n",
              " 'markov',\n",
              " 'chore',\n",
              " 'hadou',\n",
              " 'blackmer',\n",
              " 'gentleness']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa8zXn6abdXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "888683ce-c70c-44b2-bb94-227fa87cdf73"
      },
      "source": [
        "\"desecrate\" in wiki_words, \"desecrate\" in imdb_words"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAh7ZXWzbnKf",
        "colab_type": "text"
      },
      "source": [
        "# _______________________________________make embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEP9142BYnYm",
        "colab_type": "text"
      },
      "source": [
        "now we should encode the LM of IMDB :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAHgphk68ryS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = learn_lm.model[0].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDBo8VrUYxlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "068d7f91-3498-4b8e-e137-931f02f6036c"
      },
      "source": [
        "enc\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(60000, 400, padding_idx=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU3MSnulY4B7",
        "colab_type": "text"
      },
      "source": [
        "as you see above we make Embedding of word "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3xyqZI6cEDf",
        "colab_type": "text"
      },
      "source": [
        "# Generating fake movie reviews (using wiki-text model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYTjmUqY1za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"The color of the sky is\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqtgMvcqd8un",
        "colab_type": "text"
      },
      "source": [
        "<!--  --> temperature is for randomized and you decide how much words can be random."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSApjS6ScHzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f5c27dc9-b54c-4d36-a618-8b90c2d4edbb"
      },
      "source": [
        "\n",
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The color of the sky is a natural significance , for instance in the Summer of Love , the Tibetan Dream ( Buddhist epics ) , and in the Buddhist goddess Torah ( The Tree of\n",
            "The color of the sky is dark , dark , and dark , and the dark red on the sky is considered to be painted by some people . In the 1970s , Frank Befriended and the American team were looking for\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zASLzOJtcrPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "TEXT = \"my idea about this movie \"\n",
        "N_WORDS = 30\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YZu-CCyeaII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "92bfb363-b668-4651-86af-72087ffba639"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my idea about this movie  = \n",
            " \n",
            "  The idea of a film adaptation of the novel was first proposed by American novelist William Shakespeare in the early 19th century .\n",
            "my idea about this movie  = \n",
            " \n",
            "  The idea of a film adaptation of the novel was first proposed by American author Robert Oppenheimer in the 1950s . He wrote\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Kt-a12eyCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "2c4b5c33-be56-4720-f237-ff75f483ee30"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.70) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my idea about this movie  = \n",
            " \n",
            "  The history of a cinema is a matter of debate . It is a science - fiction film and is a set of several stories .\n",
            "my idea about this movie  = \n",
            " \n",
            "  The philosophy of architecture is a theory of how the modern universe begins to expand in the Universe and form a new universe . It\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43G7FZMte2hc",
        "colab_type": "text"
      },
      "source": [
        "as you see above temperature has affect on randomize of sentences ,in the first part two sentences are same but in second part sentences are different \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muf1zeBahs0Q",
        "colab_type": "text"
      },
      "source": [
        "# more example :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIEg4GVMiWrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlAdyQ4tib33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "eda71aa5-6727-47f9-e3c4-1ce5fb389c4c"
      },
      "source": [
        "TEXT = \"i liked this movie because\"\n",
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i liked this movie because of its violence . However , the film did not contain any religious imagery . It was a request from Christianity for a commercial film snipped , and this was later confirmed by the Olympic\n",
            "i liked this movie because of the film 's success . The film 's script was written by French composer Jean Bernard Clemens and was sung by Pauline Kael . The film was met with mixed reception\n",
            "i liked this movie because it \" got a good idea \" of the film . Nevertheless , it was one of the most popular film roles of the 1960s , with Gary Cooper 's portrayal as a slave as follows :\n",
            "i liked this movie because of America 's own culture of the 1950s , and the great deal between it and the American public to make it an international benefits . Although many people did not see it , it was a\n",
            "i liked this movie because it was too massive and silly and that it was not for anyone . As a result , the film was virtually forgotten . The film was released in Australia , South Africa and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg0FCj9qikG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "776e17d5-6173-455d-8168-2a3a0f059d8c"
      },
      "source": [
        "TEXT = \"I hated this movie\"\n",
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hated this movie hell = \n",
            " \n",
            "  i ' m not a teacher or a fool , but it is a whole . It 's very difficult to imagine the movie is really real . It just goes that original piece of\n",
            "I hated this movie as \" an AMC show \" . The British television weekend network BBC One , which had a high - rated television series , went on to produce a free - to - air show\n",
            "I hated this movie and wrote it as a personal wonder . \" It was the first time i really did it , \" he said . \" It 's just a little more than a tragedy , because it 's a\n",
            "I hated this movie in the United States , starring Tom Cruise in The Godfather ( 2004 ) . The Charleston Daily News reported that the film was used to watch the non -\n",
            "I hated this movie in the United States as it did in Washington , D.C. , in the United States . Instead , it focused on the American West , where the role of the\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}